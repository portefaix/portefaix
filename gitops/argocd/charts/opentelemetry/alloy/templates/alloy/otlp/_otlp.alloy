{{ define "alloy.config.otlp" }}

otelcol.processor.resourcedetection "default" {
  detectors = ["env", "system", "kubernetes_node"]

  system {
    hostname_sources = ["os"]
  }

  output {
    metrics = [otelcol.processor.transform.add_metric_datapoint_attributes.input]
    logs    = [otelcol.processor.attributes.cluster.input]
    traces  = [otelcol.processor.attributes.cluster.input]
  }
}

otelcol.processor.transform "add_metric_datapoint_attributes" {
  // Grafana Cloud Kubernetes monitoring expects Loki labels `cluster`, `pod`, and `namespace`
  error_mode = "ignore"

  metric_statements {
    context = "datapoint"
    statements = [
      "set(attributes[\"deployment.environment\"], resource.attributes[\"deployment.environment\"])",
      "set(attributes[\"service.version\"], resource.attributes[\"service.version\"])",
    ]
  }

  output {
    metrics = [otelcol.processor.attributes.cluster.input]
  }
}

otelcol.processor.attributes "cluster" {
  action {
    key = "cluster"
    value = {{ .Values.observability.cluster_name | quote }}
    action = "insert"
  }

  output {
    logs = [otelcol.processor.k8sattributes.default.input]
		metrics = [otelcol.processor.k8sattributes.default.input]
		traces = [otelcol.processor.k8sattributes.default.input]
  }
}

otelcol.processor.k8sattributes "default" {
  extract {
    metadata = [
        "k8s.namespace.name",
        "k8s.pod.name",
        "k8s.deployment.name",
        "k8s.statefulset.name",
        "k8s.daemonset.name",
        "k8s.cronjob.name",
        "k8s.job.name",
        "k8s.node.name",
        "k8s.pod.uid",
        "k8s.pod.start_time"
    ]
  }
  pod_association {
    source {
      from = "connection"
    }
  }

  output {
    metrics = [otelcol.processor.transform.default.input]
    logs    = [otelcol.processor.transform.default.input]
    traces  = [
      otelcol.processor.transform.default.input,
      otelcol.connector.host_info.default.input,
    ]
  }
}

otelcol.connector.host_info "default" {
  host_identifiers = [
    "k8s.node.name"
	]
  output {
    metrics = [otelcol.processor.batch.host_info_batch.input]
  }
}

otelcol.processor.batch "host_info_batch" {
  output {
    metrics = [otelcol.exporter.prometheus.host_info_metrics.input]
  }
}

otelcol.exporter.prometheus "host_info_metrics" {
  add_metric_suffixes = false
  forward_to = [prometheus.remote_write.metrics_service.receiver]
}

otelcol.processor.transform "default" {
  // Grafana Cloud Kubernetes monitoring expects Loki labels `cluster`, `pod`, and `namespace`
  error_mode = "ignore"

  metric_statements {
    context = "resource"
    statements = [
      "set(attributes[\"k8s.cluster.name\"], \"{{ .Values.observability.cluster_name }}\") where attributes[\"k8s.cluster.name\"] == nil",
    ]
  }

  log_statements {
    context = "resource"
    statements = [
      "set(attributes[\"pod\"], attributes[\"k8s.pod.name\"])",
      "set(attributes[\"namespace\"], attributes[\"k8s.namespace.name\"])",
      "set(attributes[\"loki.resource.labels\"], \"cluster, namespace, job, pod\")",
      "set(attributes[\"k8s.cluster.name\"], \"{{ .Values.observability.cluster_name }}\") where attributes[\"k8s.cluster.name\"] == nil",
    ]
  }

  trace_statements {
    context = "resource"
    statements = [
      "limit(attributes, 100, [])",
      "truncate_all(attributes, 4096)",
      "set(attributes[\"k8s.cluster.name\"], \"{{ .Values.observability.cluster_name }}\") where attributes[\"k8s.cluster.name\"] == nil",
    ]
  }

  trace_statements {
    context = "span"
    statements = [
      "limit(attributes, 100, [])",
      "truncate_all(attributes, 4096)",
    ]
  }

  output {
    metrics = [otelcol.processor.filter.default.input]
    logs = [otelcol.processor.filter.default.input]
    traces = [otelcol.processor.filter.default.input]
  }
}

otelcol.processor.filter "default" {
  error_mode = "ignore"
  traces {
    span = [
      "attributes[\"http.route\"] == \"/live\"",
      "attributes[\"http.route\"] == \"/healthy\"",
      "attributes[\"http.route\"] == \"/ready\"",
    ]
  }

  output {
    metrics = [otelcol.processor.batch.batch_processor.input]
    logs = [otelcol.processor.batch.batch_processor.input]
    traces = [otelcol.processor.batch.batch_processor.input]
  }
}

otelcol.processor.batch "batch_processor" {
  send_batch_size = 16384
  send_batch_max_size = 0
  timeout = "5s"
  output {
    metrics = [otelcol.processor.memory_limiter.default.input]
    logs = [otelcol.processor.memory_limiter.default.input]
    traces = [otelcol.processor.memory_limiter.default.input]
  }
}

otelcol.processor.memory_limiter "default" {
  check_interval = "1s"
  limit = "100MiB"
  output {
    metrics = [otelcol.exporter.prometheus.metrics_converter.input]
    logs = [otelcol.exporter.loki.logs_converter.input]
    traces = [otelcol.processor.attributes.traces_.input] // [otelcol.exporter.otlp.traces_service.input]
  }
}

otelcol.exporter.prometheus "metrics_converter" {
  forward_to = [prometheus.relabel.metrics_router.receiver]
}

otelcol.exporter.loki "logs_converter" {
  forward_to = [loki.process.logs_router.receiver] // [loki.process.pod_logs.receiver]
}

{{ end }}