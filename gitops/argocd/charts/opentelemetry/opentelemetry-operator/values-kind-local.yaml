# Copyright (C) Nicolas Lamirault <nicolas.lamirault@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---
opentelemetry-operator:
  collectorImage:
    repository: otel/opentelemetry-collector-contrib

  serviceMonitor:
    enabled: true
    extraLabels:
      monitoring: portefaix
    prometheusRule:
      enabled: true
      groups: []
      defaultRules:
        enabled: true
      extraLabels:
        monitoring: portefaix

  admissionWebhooks:
    enabled: true

    ## Provide the issuer kind and name to do the cert auth job.
    ## By default, OpenTelemetry Operator will use self-signer issuer.
    certManager:
      enabled: true
      # issuerRef: {}
      #   kind:
      #   name:

opentelemetrycollector:
  mode: statefulset

  extraEnvs:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName

  ports:
    - name: metric
      port: 9090
      protocol: TCP
      targetPort: 9090

  resources:
    limits:
      # cpu: 500m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 64Mi

  serviceMonitor:
    enabled: true
    extraLabels:
      monitoring: portefaix

  config:
    receivers:

      hostmetrics:
        collection_interval: 60s
        scrapers:
          cpu: {}
          load: {}
          memory: {}
          disk: {}
          filesystem: {}
          network: {}

      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268
          thrift_compact:
            endpoint: 0.0.0.0:6831

      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318

      prometheus:
        config:
          global:
            scrape_interval: 30s
            scrape_timeout: 10s
            evaluation_interval: 10s
          scrape_configs:
            - job_name: opentelemetry-collector
              scrape_interval: 30s
              static_configs:
                - targets:
                    - localhost:8888

      # zipkin:
      #   endpoint: 0.0.0.0:9411

      k8s_cluster:
        collection_interval: 60s
        distribution: kubernetes
        node_conditions_to_report: [Ready, DiskPressure, MemoryPressure, PIDPressure, NetworkUnavailable]
        allocatable_types_to_report: [cpu, memory, ephemeral-storage, storage]

      k8s_events:
        auth_type: "serviceAccount"

      kubeletstats:
        collection_interval: 60s
        auth_type: "serviceAccount"
        endpoint: "${K8S_NODE_NAME}:10250"
        insecure_skip_verify: true

      # receiver_creator:
      #    watch_observers: [k8s_observer]
      #    receivers:
      #       kubeletstats:
      #         rule: type == "k8s.node"
      #         config:
      #           collection_interval: 60s
      #           auth_type: "serviceAccount"
      #           # endpoint: "https://${K8S_NODE_NAME}:10250"
      #           # auth_type: "none"
      #           # endpoint: "http://${K8S_NODE_NAME}:10255"
      #           # insecure_skip_verify: true
      #           endpoint: "`endpoint`:`kubelet_endpoint_port`"
      #           insecure_skip_verify: true
      #           extra_metadata_labels:
      #             - container.id
      #             - k8s.volume.type
      #           metric_groups:
      #             - node
      #             - pod
      #             - volume
      #             - container

    processors:

      batch:
        send_batch_max_size: 1000
        timeout: 30s
        send_batch_size : 800

      # Data sources: traces, metrics, logs
      memory_limiter:
        limit_percentage: 70
        spike_limit_percentage: 30
        check_interval: 5s

      # metricstransform:
      #   transforms:
      #      include: .+
      #      match_type: regexp
      #      action: update
      #      operations:
      #        - action: add_label
      #          new_label: kubernetes.cluster.id
      #          new_value: kind-local
      #        - action: add_label
      #          new_label: kubernetes.name
      #          new_value: local

      # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/resourcedetectionprocessor/README.md
      # resourcedetection/gce:
      #   detectors: [env, gce, gke]
      #   timeout: 2s
      #   override: true

      k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        filter:
          node_from_env_var: K8S_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.cluster.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
        pod_association:
          - from: resource_attribute
            name: k8s.pod.uid

    exporters:

      logging:
        loglevel: info

      prometheus:
        endpoint: "0.0.0.0:9090"
        metric_expiration: 180m
        resource_to_telemetry_conversion:
          enabled: true

      # Data sources: metrics
      # prometheusremotewrite/prom:
      #   endpoint: "http://prometheus-operated.monitoring.svc.cluster.local:9090/api/v1/write"

      # prometheusremotewrite/mimir:
      #   endpoint: "http://mimir.monitoring.svc.cluster.local:9411/api/prom/push"

      # Data sources: logs
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/exporter/lokiexporter/README.md
      loki:
        endpoint: "http://loki.logging.svc.cluster.local:3100/loki/api/v1/push"
        tenant_id: "local"
        labels:
          resource:
            # Allowing 'container.name' attribute and transform it to 'container_name', which is a valid Loki label name.
            container.name: "container_name"
            k8s.cluster.name: "k8s_cluster_name"
            k8s.event.reason: "k8s_event_reason"
            k8s.object.kind: "k8s_object_kind"
            k8s.object.name: "k8s_object_name"
            k8s.object.uid: "k8s_object_uid"
            k8s.object.fieldpath: "k8s_object_fieldpath"
            k8s.object.api_version: "k8s_object_api_version"
          attributes:
            k8s.event.reason: "k8s_event_reason"
            k8s.event.action: "k8s_event_action"
            k8s.event.start_time: "k8s_event_start_time"
            k8s.event.name: "k8s_event_name"
            k8s.event.uid: "k8s_event_uid"
            k8s.namespace.name: "k8s_namespace_name"
            k8s.event.count: "k8s_event_count"
          record:
            # Adds 'traceID' as a log label, seen as 'traceid' in Loki.
            traceID: "traceid"
        # headers:
        #   "X-Custom-Header": "portefaix_homelab"

      # Data sources: traces, metrics, logs
      otlp/tempo:
        endpoint: tempo.tracing.svc.cluster.local:4317
        tls:
          insecure_skip_verify: true
          insecure: true

      # Data sources: traces, metrics, logs
      # otlp/honeycomb:
      #   endpoint: "api.honeycomb.io:443"
      #   headers:
      #     "x-honeycomb-team": "${HONEYCOMB_API_KEY}"
      #     "x-honeycomb-dataset": "portefaix-homelab" # for Metrics

      # Data sources: traces, metrics, logs
      # otlp/aspecto:
      #   endpoint: otelcol.aspecto.io:4317
      #   headers:
      #     Authorization: ${ASPECTO_API_KEY}

      # datadog:
      #   env: prod
      #   service: opentelemetry
      #   tags:
      #     - cloud:homelab
      #   api:
      #     key: ${DATADOG_API_KEY}
      #     site: datadoghq.eu

      # mezmo:
      #   ingest_url: "https://logs.logdna.com/log/ingest"
      #   ingest_key: "${MEZMO_API_KEY}"

    extensions:

      health_check: {}

      memory_ballast:
        size_in_percentage: 20

      # k8s_observer:
      #   auth_type: serviceAccount
      #   node: ${K8S_NODE_NAME}
      #   observe_pods: true
      #   observe_nodes: true

      zpages:
        endpoint: 0.0.0.0:55679

    service:

      telemetry:
        metrics:
          address: 0.0.0.0:8888

      extensions:
        - health_check
        - memory_ballast
        # - k8s_observer
        - zpages

      pipelines:

        logs:
          receivers:
            - otlp
            - k8s_events
          processors:
            - batch
            - k8sattributes
            - memory_limiter
          exporters:
            - logging
            # - loki

        metrics:
          receivers:
            - hostmetrics
            - prometheus
            - k8s_cluster
            - kubeletstats
            # - receiver_creator
            - otlp
          processors:
            - memory_limiter
            # - metricstransform
            - k8sattributes
            # - resourcedetection/gce
            - batch
          exporters:
            - logging
            - prometheus
            # - prometheusremotewrite/prom
            # - prometheusremotewrite/mimir
            # - datadog

        traces:
          receivers:
            - otlp
          processors:
            - batch
            - k8sattributes
            - memory_limiter
          exporters:
            - logging
            # - otlp/tempo
